import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import os
from io import StringIO
from statsmodels.tsa.seasonal import seasonal_decompose
from sklearn.tree import plot_tree # Necess√°rio para a fun√ß√£o plot_tree, embora n√£o seja usada diretamente para o dashboard

# --- Caminhos dos arquivos da an√°lise ---
SALES_TS_SAVE_PATH = 'sales_time_series.joblib'
DECOMPOSITION_SAVE_PATH_TREND = 'ts_trend.joblib'
DECOMPOSITION_SAVE_PATH_SEASONAL = 'ts_seasonal.joblib'
DECOMPOSITION_SAVE_PATH_RESIDUAL = 'ts_residual.joblib'
MONTHLY_SALES_SAVE_PATH = 'monthly_sales_summary.joblib'
COLUMNS_MAPPING_SAVE_PATH = 'columns_mapping.joblib'

# Caminhos para o MELHOR modelo de regress√£o
BEST_MODEL_SAVE_PATH = 'best_sales_prediction_model.joblib'
MODEL_TYPE_SAVE_PATH = 'model_type.joblib' # Para saber se √© DT, RF ou XGB
DT_FEATURES_SAVE_PATH = 'decision_tree_features.joblib' # Nomes das features
TREE_IMAGE_PATH = 'decision_tree_plot_tree.png' # Caminho para a imagem da √°rvore (se o melhor for DT)
MODEL_METRICS_SAVE_PATH = 'model_metrics.joblib' # Caminho para carregar as m√©tricas do modelo

# --- T√≠tulo da Aplica√ß√£o ---
st.set_page_config(
    page_title="An√°lise de Sazonalidade e Previs√£o de Vendas",
    layout="wide",
    initial_sidebar_state="auto"
)
st.title("üìà An√°lise de Sazonalidade das Vendas e Previs√£o de Vendas")
st.markdown("Este aplicativo analisa padr√µes sazonais em dados de vendas e permite interagir com o modelo de previs√£o mais eficaz.")

# --- Fun√ß√µes Auxiliares para An√°lise de Sazonalidade ---

@st.cache_data
def perform_seasonality_analysis(df: pd.DataFrame, columns_mapping: dict, data_col_name: str, sales_col_name: str):
    df_processed = df.copy()

    # Tenta renomear se as colunas j√° n√£o estiverem no formato mapeado
    if not all(col in df_processed.columns for col in [data_col_name, sales_col_name]):
        # Apenas as chaves que realmente existem em df_processed.columns ser√£o renomeadas
        df_processed.rename(columns={k: v for k, v in columns_mapping.items() if k in df_processed.columns}, inplace=True)
        if not all(col in df_processed.columns for col in [data_col_name, sales_col_name]):
            st.error(f"Erro: As colunas essenciais '{data_col_name}' (Data do Pedido) ou '{sales_col_name}' (Valor de Venda) n√£o foram encontradas no dataset ap√≥s a tentativa de renomear.")
            return None, None, None, None, None

    # Tratamento de nulos antes de converter tipos
    df_processed.dropna(subset=[data_col_name, sales_col_name], inplace=True)
    if df_processed.empty:
        st.warning("O dataset est√° vazio ap√≥s remover linhas com valores ausentes nas colunas essenciais para a an√°lise de sazonalidade.")
        return None, None, None, None, None

    # Convers√£o de tipos: Data_Pedido no formato 'DD/MM/YYYY' e Valor_Venda num√©rico
    df_processed[data_col_name] = pd.to_datetime(df_processed[data_col_name], format='%d/%m/%Y', errors='coerce')
    df_processed[sales_col_name] = pd.to_numeric(df_processed[sales_col_name], errors='coerce')
    df_processed.dropna(subset=[data_col_name, sales_col_name], inplace=True) # Remover nulos ap√≥s coer√ß√£o
    
    if df_processed.empty:
        st.warning("O dataset est√° vazio ap√≥s a convers√£o de tipos de dados.")
        return None, None, None, None, None

    sales_ts = df_processed.set_index(data_col_name)[sales_col_name].resample('MS').sum()
    monthly_sales_avg = sales_ts.groupby(sales_ts.index.month).mean() # type: ignore
    # No analise_e_modelagem.py, o monthly_sales_avg.index √© definido com nomes de m√™s.
    
    trend, seasonal, residual = None, None, None
    try:
        if len(sales_ts) >= 2 * 12: # Pelo menos 2 ciclos anuais completos
            decomposition = seasonal_decompose(sales_ts, model='multiplicative', period=12, extrapolate_trend='freq') # type: ignore
            trend = decomposition.trend
            seasonal = decomposition.seasonal
            residual = decomposition.resid
        else:
            st.warning("S√©rie temporal muito curta para decomposi√ß√£o sazonal completa (precisa de pelo menos 24 meses para sazonalidade anual).")
    except Exception as e:
        st.error(f"Erro ao realizar decomposi√ß√£o sazonal: {e}")
        st.warning("Certifique-se de que os dados de tempo e vendas est√£o corretos e que a s√©rie tem dados suficientes.")

    return sales_ts, monthly_sales_avg, trend, seasonal, residual

def plot_seasonality_results(sales_ts, monthly_sales_avg, trend, seasonal, residual, title_suffix=""):
    """Plota os gr√°ficos de sazonalidade no Streamlit."""
    if sales_ts is None or sales_ts.empty:
        st.warning(f"N√£o h√° dados para plotar a an√°lise de sazonalidade {title_suffix}.")
        return

    st.subheader(f"S√©rie Temporal de Vendas {title_suffix}")
    fig1, ax1 = plt.subplots(figsize=(24, 5))
    ax1.plot(sales_ts)
    ax1.set_title(f'S√©rie Temporal de Vendas Agregadas Mensalmente {title_suffix}')
    ax1.set_xlabel('Data')
    ax1.set_ylabel('Valor de Venda')
    ax1.grid(True)
    st.pyplot(fig1)
    plt.close(fig1)

    st.subheader(f"Padr√£o Sazonal M√©dio Mensal {title_suffix}")
    if monthly_sales_avg is not None and not monthly_sales_avg.empty:
        fig2, ax2 = plt.subplots(figsize=(24, 5))
        sns.barplot(x=monthly_sales_avg.index, y=monthly_sales_avg.values, palette='viridis', ax=ax2)
        ax2.set_title(f'Vendas M√©dias por M√™s (Padr√£o Sazonal) {title_suffix}')
        ax2.set_xlabel('M√™s')
        ax2.set_ylabel('Valor de Venda M√©dio')
        ax2.grid(axis='y', linestyle='--', alpha=0.7)
        st.pyplot(fig2)
        plt.close(fig2)

        st.subheader(f"Destaques da Sazonalidade {title_suffix}")
        
        peak_month_name = monthly_sales_avg.idxmax()
        peak_value = monthly_sales_avg.max()

        low_month_name = monthly_sales_avg.idxmin()
        low_value = monthly_sales_avg.min()

        st.info(f"**M√™s de Pico de Vendas:** **{peak_month_name}** com vendas m√©dias de **R$ {peak_value:,.2f}**.")
        st.info(f"**M√™s de Baixa de Vendas:** **{low_month_name}** com vendas m√©dias de **R$ {low_value:,.2f}**.")
    else:
        st.warning(f"N√£o foi poss√≠vel calcular destaques de sazonalidade para o dataset {title_suffix}. Verifique os dados.")

    st.subheader(f"Componentes da Decomposi√ß√£o Sazonal {title_suffix}")
    if trend is not None and seasonal is not None and residual is not None:
        fig_decomp, axes = plt.subplots(4, 1, figsize=(24, 5), sharex=True)

        axes[0].plot(sales_ts)
        axes[0].set_title('Original')
        axes[0].grid(True)

        axes[1].plot(trend)
        axes[1].set_title('Tend√™ncia')
        axes[1].grid(True)

        axes[2].plot(seasonal)
        axes[2].set_title('Sazonalidade')
        axes[2].grid(True)

        axes[3].plot(residual)
        axes[3].set_title('Res√≠duo')
        axes[3].grid(True)

        plt.tight_layout()
        st.pyplot(fig_decomp)
        plt.close(fig_decomp)

        st.info("A **Tend√™ncia** mostra a dire√ß√£o geral das vendas.")
        st.info("A **Sazonalidade** revela o padr√£o repetitivo.")
        st.info("O **Res√≠duo** indica flutua√ß√µes aleat√≥rias ou ru√≠do.")
    else:
        st.warning(f"A decomposi√ß√£o sazonal n√£o p√¥de ser gerada para o dataset {title_suffix}. Isso pode ocorrer se a s√©rie temporal for muito curta ou n√£o tiver dados suficientes para identificar um ciclo sazonal completo.")

# --- Carregar Resultados da An√°lise do Dataset Original ---
@st.cache_resource
def load_original_analysis_results():
    try:
        sales_ts = joblib.load(SALES_TS_SAVE_PATH)
        monthly_sales_avg = joblib.load(MONTHLY_SALES_SAVE_PATH)
        columns_mapping = joblib.load(COLUMNS_MAPPING_SAVE_PATH)

        trend = None
        seasonal = None
        residual = None
        if os.path.exists(DECOMPOSITION_SAVE_PATH_TREND) and \
           os.path.exists(DECOMPOSITION_SAVE_PATH_SEASONAL) and \
           os.path.exists(DECOMPOSITION_SAVE_PATH_RESIDUAL):
            trend = joblib.load(DECOMPOSITION_SAVE_PATH_TREND)
            seasonal = joblib.load(DECOMPOSITION_SAVE_PATH_SEASONAL)
            residual = joblib.load(DECOMPOSITION_SAVE_PATH_RESIDUAL)

        return sales_ts, monthly_sales_avg, columns_mapping, trend, seasonal, residual
    except FileNotFoundError as e:
        st.error(f"Erro: Arquivo de an√°lise do dataset original n√£o encontrado. Rode `analise_e_modelagem.py` primeiro para ger√°-los.")
        st.stop()
    except Exception as e:
        st.error(f"Ocorreu um erro ao carregar os resultados da an√°lise do dataset original: {e}")
        st.stop()

# --- Carregar o MELHOR Modelo e suas Features/M√©tricas ---
@st.cache_resource
def load_best_model():
    try:
        model = joblib.load(BEST_MODEL_SAVE_PATH)
        model_type = joblib.load(MODEL_TYPE_SAVE_PATH)
        feature_names = joblib.load(DT_FEATURES_SAVE_PATH) # Nomes das features s√£o os mesmos para DT/RF/XGB
        metrics = joblib.load(MODEL_METRICS_SAVE_PATH) 
        return model, model_type, feature_names, metrics
    except FileNotFoundError:
        st.error(f"Erro: Arquivos do modelo de previs√£o n√£o encontrados. Certifique-se de que '{BEST_MODEL_SAVE_PATH}', '{MODEL_TYPE_SAVE_PATH}', '{DT_FEATURES_SAVE_PATH}' e '{MODEL_METRICS_SAVE_PATH}' foram gerados pelo script de an√°lise.")
        st.stop()
    except Exception as e:
        st.error(f"Ocorreu um erro ao carregar o modelo de previs√£o: {e}")
        st.stop()

original_sales_ts, original_monthly_sales_avg, columns_mapping_loaded, \
original_trend, original_seasonal, original_residual = load_original_analysis_results()

best_regressor_model, best_model_type, model_feature_names, model_metrics = load_best_model()


# --- Layout da Aplica√ß√£o com Abas ---
tab_sazonalidade_original, tab_sazonalidade_upload, tab_model_info, tab_previsao_vendas = st.tabs([
    "Sazonalidade (Original)",
    "Sazonalidade (Novo Dataset)",
    "Informa√ß√µes do Modelo",
    "Previs√£o de Vendas"
])

with tab_sazonalidade_original:
    st.header("An√°lise de Sazonalidade do Dataset Original")
    st.markdown("Esta se√ß√£o mostra a an√°lise de sazonalidade do dataset `dataset.csv`.")
    plot_seasonality_results(original_sales_ts, original_monthly_sales_avg, 
                             original_trend, original_seasonal, original_residual, "(Dataset Original)")

with tab_sazonalidade_upload:
    st.header("Analisar Novo Dataset para Sazonalidade")
    st.markdown("Fa√ßa upload de um arquivo CSV para analisar a sazonalidade em seus pr√≥prios dados de vendas.")
    st.info("**Importante:** O arquivo CSV deve conter colunas de 'Data do Pedido' e 'Valor de Venda'.")

    uploaded_file_sazonalidade = st.file_uploader("Escolha um arquivo CSV para an√°lise de sazonalidade", type="csv", key="sazonalidade_uploader")

    if uploaded_file_sazonalidade is not None:
        try:
            # Delimitador AGORA √© v√≠rgula (,) para o NOVO dataset
            uploaded_df_raw_saz = pd.read_csv(uploaded_file_sazonalidade, sep=',', header=0)
            st.write("Pr√©-visualiza√ß√£o do Dataset Carregado:")
            st.dataframe(uploaded_df_raw_saz.head())
            
            st.write(f"Dataset carregado com {len(uploaded_df_raw_saz)} linhas e {len(uploaded_df_raw_saz.columns)} colunas.")
            
            if st.button("Gerar An√°lise de Sazonalidade (Novo Dataset)", key="run_saz_analysis"):
                uploaded_sales_ts, uploaded_monthly_sales_avg, \
                uploaded_trend, uploaded_seasonal, uploaded_residual = \
                    perform_seasonality_analysis(uploaded_df_raw_saz.copy(), columns_mapping_loaded, 'Data_Pedido', 'Valor_Venda')
                
                if uploaded_sales_ts is not None and not uploaded_sales_ts.empty:
                    st.success("An√°lise de sazonalidade gerada com sucesso para o dataset carregado!")
                    plot_seasonality_results(uploaded_sales_ts, uploaded_monthly_sales_avg,
                                             uploaded_trend, uploaded_seasonal, uploaded_residual, "(Dataset Carregado)")
                else:
                    st.warning("N√£o foi poss√≠vel realizar a an√°lise de sazonalidade completa no dataset carregado. Verifique o formato das colunas 'Data do Pedido' e 'Valor de Venda' e se h√° dados suficientes.")

        except Exception as e:
            st.error(f"Erro ao processar o arquivo CSV ou realizar a an√°lise de sazonalidade: {e}")
            st.warning("Certifique-se de que o arquivo √© um CSV v√°lido, com o delimitador correto (v√≠rgula) e com as colunas esperadas.")


with tab_model_info: # Aba renomeada
    st.header("Informa√ß√µes e Avalia√ß√£o do Modelo de Previs√£o")
    st.markdown(f"O modelo de previs√£o de vendas mais eficaz encontrado √© um **{best_model_type}**.")

    # Exibir as m√©tricas de avalia√ß√£o do modelo
    st.subheader("M√©tricas de Avalia√ß√£o do Modelo")
    st.markdown(f"**RMSE (Root Mean Squared Error):** `R$ {model_metrics['rmse']:.2f}`")
    st.markdown(f"**MSE (Mean Squared Error):** `{model_metrics['mse']:.2f}`")
    st.markdown(f"**R¬≤ (Coeficiente de Determina√ß√£o):** `{model_metrics['r2']:.2f}`")
    st.info("""
    * **RMSE:** Quanto menor, melhor. Representa o erro m√©dio das previs√µes na mesma unidade do Valor de Venda.
    * **MSE:** Quanto menor, melhor. √â o quadrado do RMSE, penaliza erros maiores.
    * **R¬≤:** Quanto mais pr√≥ximo de 1, melhor. Indica a propor√ß√£o da vari√¢ncia na vari√°vel dependente que √© previs√≠vel a partir das vari√°veis independentes. Um R¬≤ de 0.80 significa que 80% da variabilidade das vendas √© explicada pelo modelo.
    """)

    # Exibir a imagem da √°rvore SOMENTE se o melhor modelo for uma DecisionTreeRegressor
    if best_model_type == "DecisionTreeRegressor":
        st.subheader("Visualiza√ß√£o da √Årvore de Decis√£o")
        st.markdown("Esta √© a √°rvore de decis√£o que foi selecionada como o melhor modelo. Ela foi treinada para prever o **Valor de Venda** e pode servir como aux√≠lio visual na compreens√£o das caracter√≠sticas do dataset.")
        if os.path.exists(TREE_IMAGE_PATH):
            st.image(TREE_IMAGE_PATH, caption="√Årvore de Decis√£o do Modelo (Profundidade Limitada para Visualiza√ß√£o)", use_container_width=True)
            st.info("A √°rvore exibe as regras que um modelo de regress√£o usa para estimar um valor. Cada n√≥ representa uma condi√ß√£o em uma caracter√≠stica, e as folhas representam o valor m√©dio previsto para as amostras que chegam √†quele n√≥.")
        else:
            st.warning(f"A imagem da √°rvore de decis√£o ('{TREE_IMAGE_PATH}') n√£o foi encontrada. Ela s√≥ √© gerada se a √Årvore de Decis√£o for o melhor modelo.")
    else:
        st.info(f"O melhor modelo selecionado √© um **{best_model_type}**. Modelos de ensemble como o Random Forest ou XGBoost s√£o compostos por muitas √°rvores e n√£o possuem uma √∫nica √°rvore para visualiza√ß√£o direta, mas geralmente oferecem maior robustez e efic√°cia.")


with tab_previsao_vendas: # Aba renomeada
    st.header("Fa√ßa uma Previs√£o de Venda com o Modelo de Vendas")
    st.markdown(f"Experimente diferentes valores para as caracter√≠sticas e veja qual o **Valor de Venda** previsto pelo modelo **{best_model_type}**.")

    # Obter os valores √∫nicos para as colunas categ√≥ricas do dataset original
    try:
        # Carregar o DataFrame original para obter valores √∫nicos
        df_original_full = pd.read_csv('dataset.csv', sep=',', header=0) # <-- MUDAR AQUI PARA V√çRGULA
        # Renomear as colunas (apenas as que existem no novo dataset)
        df_original_full.rename(columns={k: v for k, v in columns_mapping_loaded.items() if k in df_original_full.columns}, inplace=True)
        
        # Lista de colunas categ√≥ricas que voc√™ est√° usando como features
        # Baseado nas 'features_columns' definidas no analise_e_modelagem.py
        categorical_features_for_model_display = ['Segmento', 'Pais', 'Cidade', 'Estado', 'Categoria', 'SubCategoria']

        options = {}
        for col in categorical_features_for_model_display:
            if col in df_original_full.columns:
                # Tratar nulos e garantir que sejam strings antes de unique() e sorted()
                options[col] = [str(x) for x in df_original_full[col].dropna().unique()]
                # IMPORTANTE: Filtrar op√ß√µes com muitas categorias (alta cardinalidade)
                # Para evitar dropdowns gigantes e problemas de performance/interface
                if len(options[col]) > 100: # Limite arbitr√°rio, ajuste se necess√°rio
                    st.warning(f"Coluna '{col}' tem muitas categorias ({len(options[col])}). Exibindo apenas as 100 mais frequentes para evitar sobrecarga na interface. Considere agrup√°-las.")
                    top_categories = df_original_full[col].value_counts().nlargest(100).index.tolist()
                    options[col] = [str(x) for x in top_categories]
                if not options[col]: # Se a lista ainda estiver vazia ap√≥s tratamento de nulos/filtragem
                    options[col] = [f"Nenhum Valor Encontrado para {col}"] # Fallback
            else:
                st.warning(f"Coluna '{col}' n√£o encontrada no dataset original para preencher op√ß√µes. Usando valores padr√£o.")
                # Fallbacks para colunas ausentes
                if col == 'Segmento': options[col] = ["Consumer", "Corporate", "Home Office"]
                elif col == 'Pais': options[col] = ["United States", "Canada", "Brazil"]
                elif col == 'Cidade': options[col] = ["New York", "Los Angeles", "Toronto"]
                elif col == 'Estado': options[col] = ["California", "New York", "Ontario"]
                elif col == 'Categoria': options[col] = ["Office Supplies", "Furniture", "Technology"]
                elif col == 'SubCategoria': options[col] = ["Art", "Chairs", "Phones"]
                else: options[col] = ["Default"]

    except Exception as e:
        st.error(f"Erro ao carregar o dataset original para obter op√ß√µes de sele√ß√£o: {e}")
        st.warning("Usando valores padr√£o para todas as op√ß√µes de sele√ß√£o.")
        options = {
            'Segmento': ["Consumer", "Corporate", "Home Office"],
            'Pais': ["United States", "Canada", "Brazil"],
            'Cidade': ["New York", "Los Angeles", "Toronto"],
            'Estado': ["California", "New York", "Ontario"],
            'Categoria': ["Office Supplies", "Furniture", "Technology"],
            'SubCategoria': ["Art", "Chairs", "Phones"],
        }

    # Controles de entrada para as features
    # AS COLUNAS NUM√âRICAS 'Quantidade', 'Desconto', 'Custo_Envio' N√ÉO EST√ÉO MAIS DISPON√çVEIS
    col1, col2 = st.columns(2) # Reduzido para 2 colunas, pois h√° menos inputs

    with col1:
        segmento_input = st.selectbox("Segmento", sorted(options['Segmento']))
        pais_input = st.selectbox("Pa√≠s", sorted(options['Pais']))
        categoria_input = st.selectbox("Categoria", sorted(options['Categoria']))
    
    with col2:
        cidade_input = st.selectbox("Cidade", sorted(options['Cidade']))
        estado_input = st.selectbox("Estado", sorted(options['Estado']))
        subcategoria_input = st.selectbox("SubCategoria", sorted(options['SubCategoria']))

    st.markdown("---") # Separador visual

    # IMPORTANTE: N√£o h√° mais campos num√©ricos como Quantidade, Desconto, Custo_Envio
    # Se o modelo depender apenas de categ√≥ricas, a previs√£o ser√° menos granular.
    # Se voc√™ quiser adicionar inputs num√©ricos, precisar√° de novas features num√©ricas no dataset.

    if st.button("Obter Previs√£o de Venda"):
        # Criar um DataFrame para a entrada do usu√°rio
        input_data = pd.DataFrame({
            'Segmento': [segmento_input],
            'Pais': [pais_input],
            'Cidade': [cidade_input],
            'Estado': [estado_input],
            'Categoria': [categoria_input],
            'SubCategoria': [subcategoria_input],
            # As seguintes colunas N√ÉO est√£o no novo dataset e foram removidas do input_data:
            # 'Quantidade', 'Desconto', 'Custo_Envio', 'Prioridade_Pedido'
        })

        # Categoriais para One-Hot Encoding no Streamlit
        # Alinhado com as features usadas no analise_e_modelagem.py
        categorical_features_for_model = ['Segmento', 'Pais', 'Cidade', 'Estado', 'Categoria', 'SubCategoria']

        input_encoded = pd.get_dummies(input_data, columns=categorical_features_for_model)

        # Reindexar para garantir que todas as colunas de model_feature_names estejam presentes
        # e preencher com 0 onde n√£o houver correspond√™ncia. Isso √© CR√çTICO.
        input_processed = input_encoded.reindex(columns=model_feature_names, fill_value=0)

        try:
            predicted_sales = best_regressor_model.predict(input_processed)[0]
            st.success(f"O **Valor de Venda Previsto** pelo modelo √© de: **R$ {predicted_sales:,.2f}**")
            st.info("Lembre-se que esta √© uma previs√£o baseada nos padr√µes aprendidos pelo modelo e pode n√£o refletir a realidade com 100% de precis√£o.")
            st.warning("Com menos features num√©ricas no dataset, a granularidade e a efic√°cia da previs√£o podem ser limitadas.")
        except Exception as e:
            st.error(f"Erro ao fazer a previs√£o: {e}")
            st.warning("Verifique se o modelo foi carregado corretamente e se as colunas de entrada correspondem √†s esperadas pelo modelo.")


st.markdown("---")
st.markdown("Desenvolvido por J√°rio Lima com Streamlit.")